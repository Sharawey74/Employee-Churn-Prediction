# AI Project - Employee Turnover Prediction

## üéØ Project Overview

This project is a comprehensive machine learning pipeline for predicting employee turnover using **Random Forest and XGBoost** algorithms. The project has been optimized to focus exclusively on these two high-performing tree-based models, providing automated model comparison, hyperparameter optimization, and comprehensive evaluation.

### Key Features
- **Focused Algorithm Set**: Random Forest and XGBoost only for optimal performance
- **Automated Model Selection**: Best model identification based on cross-validation scores
- **Comprehensive Evaluation**: Multiple metrics with detailed performance analysis
- **Organized Structure**: Clean project organization with dedicated directories
- **JSON Outputs**: Structured results in JSON format for easy integration
- **Validation Tools**: Comprehensive validation and debugging utilities

## üìÅ Directory Structure

```
AI-Project/
‚îú‚îÄ‚îÄ üìä data/                          # Dataset storage
‚îÇ   ‚îú‚îÄ‚îÄ raw/                          # Original datasets
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ employee_data.csv         # Primary training data (11,413 rows, 28 features)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample_customer_churn.csv # Alternative dataset
‚îÇ   ‚îî‚îÄ‚îÄ processed/                    # Cleaned and engineered datasets
‚îÇ       ‚îú‚îÄ‚îÄ balanced_data.csv         # Class-balanced dataset
‚îÇ       ‚îú‚îÄ‚îÄ feature_engineered_data.csv # Final training dataset
‚îÇ       ‚îú‚îÄ‚îÄ feature_info.json         # Feature engineering metadata
‚îÇ       ‚îî‚îÄ‚îÄ processed_data.csv        # Intermediate processed data
‚îú‚îÄ‚îÄ ü§ñ models/                        # Model artifacts (RF & XGBoost only)
‚îÇ   ‚îú‚îÄ‚îÄ random_forest_model.pkl      # Trained Random Forest
‚îÇ   ‚îú‚îÄ‚îÄ xgboost_model.pkl           # Trained XGBoost
‚îÇ   ‚îú‚îÄ‚îÄ best_parameters.pkl          # Optimal hyperparameters
‚îÇ   ‚îú‚îÄ‚îÄ evaluation_data.pkl          # Train/test splits
‚îÇ   ‚îú‚îÄ‚îÄ model_registry_rf_xgb.json   # Model metadata
‚îÇ   ‚îú‚îÄ‚îÄ random_forest/              # RF-specific files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_importance.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hyperparameters.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_info.md
‚îÇ   ‚îî‚îÄ‚îÄ xgboost/                   # XGBoost-specific files
‚îÇ       ‚îú‚îÄ‚îÄ feature_importance.json
‚îÇ       ‚îú‚îÄ‚îÄ hyperparameters.json
‚îÇ       ‚îú‚îÄ‚îÄ metrics.json
‚îÇ       ‚îî‚îÄ‚îÄ model_info.md
‚îú‚îÄ‚îÄ üìÑ json/                        # All JSON outputs
‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.json       # RF vs XGBoost comparison
‚îÇ   ‚îú‚îÄ‚îÄ best_parameters.json       # Hyperparameters in JSON format
‚îÇ   ‚îú‚îÄ‚îÄ cv_results.json            # Cross-validation scores
‚îÇ   ‚îú‚îÄ‚îÄ model_summary.json         # Training summary
‚îÇ   ‚îú‚îÄ‚îÄ test_results.json          # Test evaluation metrics
‚îÇ   ‚îú‚îÄ‚îÄ random_forest_feature_importance.json
‚îÇ   ‚îî‚îÄ‚îÄ xgboost_feature_importance.json
‚îú‚îÄ‚îÄ üìà results/                     # Training results and visualizations
‚îÇ   ‚îú‚îÄ‚îÄ figures/                   # Model performance plots
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.png   # Performance comparison chart
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ roc_curves.png         # ROC curves visualization
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ target_distribution.png # Target variable distribution
‚îÇ   ‚îú‚îÄ‚îÄ reports/                   # Generated reports
‚îÇ   ‚îî‚îÄ‚îÄ metrics/                   # Performance metrics
‚îú‚îÄ‚îÄ üîß src/                        # Core modules (updated for RF & XGBoost)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # Configuration (RF & XGBoost only)
‚îÇ   ‚îú‚îÄ‚îÄ model_trainer.py          # Training pipeline (restricted)
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py            # Data loading utilities
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py    # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py              # Model evaluation
‚îÇ   ‚îî‚îÄ‚îÄ visualizer.py             # Visualization tools
‚îú‚îÄ‚îÄ üöÄ main/                       # Execution scripts
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Full pipeline (RF & XGBoost)
‚îÇ   ‚îú‚îÄ‚îÄ rf_xgb_trainer.py         # Quick trainer script
‚îÇ   ‚îî‚îÄ‚îÄ quick_start.py            # Simplified execution
‚îú‚îÄ‚îÄ üîç validations/                # Validation and debugging scripts
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ analyze_cv.py             # Cross-validation analysis
‚îÇ   ‚îú‚îÄ‚îÄ analyze_pkl_detailed.py   # Detailed PKL file analysis
‚îÇ   ‚îú‚îÄ‚îÄ analyze_pkl_files.py      # Basic PKL file analysis
‚îÇ   ‚îú‚îÄ‚îÄ check_regularization.py   # Regularization parameter analysis
‚îÇ   ‚îú‚îÄ‚îÄ debug_paths.py            # Path debugging utilities
‚îÇ   ‚îú‚îÄ‚îÄ debug_trainer.py          # ModelTrainer debugging
‚îÇ   ‚îú‚îÄ‚îÄ path_demo.py              # Path navigation demonstration
‚îÇ   ‚îú‚îÄ‚îÄ setup.py                  # Project setup script
‚îÇ   ‚îú‚îÄ‚îÄ simple_validation.py      # Simple validation tests
‚îÇ   ‚îú‚îÄ‚îÄ validate_restructure.py   # Complete project validation
‚îÇ   ‚îî‚îÄ‚îÄ validation_output.txt     # Validation results log
‚îú‚îÄ‚îÄ üß™ Testing/                    # Unit tests and integration tests
‚îÇ   ‚îú‚îÄ‚îÄ test_paths.py             # Path testing utilities
‚îÇ   ‚îú‚îÄ‚îÄ test_01_string_formatting.py
‚îÇ   ‚îú‚îÄ‚îÄ test_02_model_trainer_return.py
‚îÇ   ‚îú‚îÄ‚îÄ test_03_fixed_wrapper.py
‚îÇ   ‚îú‚îÄ‚îÄ test_04_complete_validation.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ üìì notebooks/                  # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploratory_analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_class_imbalance_analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_model_training.ipynb      # RF & XGBoost focus
‚îÇ   ‚îú‚îÄ‚îÄ 05_model_evaluation.ipynb    # Comparison analysis
‚îÇ   ‚îî‚îÄ‚îÄ 06_ModelTrainer_Fix_and_Integration.ipynb
‚îú‚îÄ‚îÄ üõ†Ô∏è utils/                      # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ helpers.py
‚îÇ   ‚îú‚îÄ‚îÄ plotting.py
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py
‚îú‚îÄ‚îÄ ‚úÖ validation/                  # Legacy validation scripts
‚îî‚îÄ‚îÄ üìã Documentation/               # Project documentation
    ‚îú‚îÄ‚îÄ README.md
    ‚îî‚îÄ‚îÄ requirements.txt
```

## üöÄ Usage Instructions

### Quick Start (Recommended)

#### Method 1: Quick Trainer Script
```bash
# Quick training with default settings
python main/rf_xgb_trainer.py

# With custom data and optimization
python main/rf_xgb_trainer.py --data-path data/raw/employee_data.csv --optimization random_search
```

#### Method 2: Full Pipeline
```bash
# Full pipeline with all steps
python main/main.py --optimization random_search

# Train specific models only
python main/main.py --models random_forest xgboost
```

#### Method 3: Python Import
```python
from main.rf_xgb_trainer import quick_train_rf_xgb

# Train and compare models
results = quick_train_rf_xgb(
    data_path='data/raw/employee_data.csv',
    optimization='random_search'
)

# Access best model
best_model = results['best_model']
best_name = results['best_model_name']
```

### Validation and Debugging

#### Run All Validations
```bash
# Complete project validation
python -m validations.validate_restructure

# Simple validation tests
python -m validations.simple_validation
```

#### Analyze Project Components
```bash
# Cross-validation analysis
python -m validations.analyze_cv

# PKL file analysis (detailed)
python -m validations.analyze_pkl_detailed

# Regularization analysis
python -m validations.check_regularization

# Debug path issues
python -m validations.debug_paths

# Test ModelTrainer functionality
python -m validations.debug_trainer
```

#### Path Navigation Demo
```bash
# Understand path navigation concepts
python -m validations.path_demo
```

### Check Evaluation Results

#### JSON Results
- **Model Comparison**: `json/model_comparison.json`
- **Cross-Validation**: `json/cv_results.json`
- **Test Results**: `json/test_results.json`
- **Feature Importance**: `json/{model}_feature_importance.json`

#### Visualizations
- **Performance Charts**: `results/figures/model_comparison.png`
- **ROC Curves**: `results/figures/roc_curves.png`
- **Target Distribution**: `results/figures/target_distribution.png`

#### Model Artifacts
- **Best Model**: Automatically identified and saved
- **Hyperparameters**: `models/best_parameters.pkl` and `json/best_parameters.json`
- **Model Registry**: `models/model_registry_rf_xgb.json`

## üì¶ Dependencies

### Core Requirements
```txt
pandas>=1.5.0
numpy>=1.23.0
scipy>=1.9.0
scikit-learn>=1.1.0
imbalanced-learn>=0.9.0
xgboost>=1.6.0
matplotlib>=3.5.0
seaborn>=0.11.0
plotly>=5.10.0
jupyterlab>=3.4.0
ipywidgets>=8.0.0
tqdm>=4.64.0
joblib>=1.1.0
optuna>=3.0.0
shap>=0.41.0
```

### Installation
```bash
# Install from requirements file
pip install -r requirements.txt

# Or install from setup script
python validations/setup.py install

# Or install in development mode
pip install -e .
```

## üéØ Model Configuration

### Random Forest Hyperparameters
- **n_estimators**: [100, 200, 300, 400, 500]
- **max_depth**: [10, 20, 30, 40, None]
- **min_samples_split**: [2, 5, 10, 15]
- **min_samples_leaf**: [1, 2, 4, 8]
- **max_features**: ['sqrt', 'log2', None]
- **bootstrap**: [True, False]

### XGBoost Hyperparameters
- **n_estimators**: [100, 200, 300, 400, 500]
- **learning_rate**: [0.01, 0.05, 0.1, 0.15, 0.2]
- **max_depth**: [3, 4, 5, 6, 7, 8]
- **subsample**: [0.8, 0.85, 0.9, 0.95, 1.0]
- **colsample_bytree**: [0.8, 0.85, 0.9, 0.95, 1.0]
- **reg_alpha**: [0, 0.01, 0.1, 0.5, 1.0] (L1 regularization)
- **reg_lambda**: [0, 0.01, 0.1, 0.5, 1.0] (L2 regularization)

## üîÑ Cross-Validation & Regularization

### Cross-Validation Setup
- **Method**: 5-fold StratifiedKFold
- **Scoring**: ROC-AUC (primary), F1-score (secondary)
- **Iterations**: 100 (RandomizedSearchCV)
- **Parallel Processing**: Full CPU utilization
- **Random State**: Fixed for reproducibility

### Regularization Techniques
- **Random Forest**: Tree depth limits, sample splits, bootstrap sampling
- **XGBoost**: L1/L2 regularization, subsampling, column sampling
- **Early Stopping**: Prevented through proper validation

## üìä Performance Metrics

Both models are evaluated using:
- **Accuracy**: Overall prediction correctness
- **Precision**: True positive rate (weighted average)
- **Recall**: Sensitivity (weighted average)
- **F1-Score**: Harmonic mean of precision/recall
- **ROC-AUC**: Area under ROC curve
- **Cross-Validation Score**: 5-fold CV performance

## üèÜ Model Selection Criteria

1. **Primary**: Cross-validation ROC-AUC score
2. **Secondary**: Test set F1-score
3. **Tertiary**: Test set accuracy
4. **Considerations**: Training time, interpretability, feature importance

## üìã Output Storage

### Models Directory
- **Trained Models**: `{model_name}_model.pkl`
- **Hyperparameters**: `best_parameters.pkl`
- **Evaluation Data**: `evaluation_data.pkl`
- **Model-Specific**: `{model_name}/` subdirectories

### JSON Directory
- **All Results**: Structured JSON format
- **Feature Importance**: Per-model feature rankings
- **Comparison Data**: Model performance comparisons
- **Metadata**: Training configuration and timestamps

### Results Directory
- **Visualizations**: `figures/` subdirectory
- **Reports**: Generated analysis reports
- **Metrics**: Detailed performance metrics

## üîß Notes

### Validation Scripts
- All validation and debug scripts are now organized under `validations/`
- Use Python module syntax: `python -m validations.script_name`
- Scripts are self-contained with proper path handling
- Comprehensive validation available via `validate_restructure.py`

### Path Handling
- All scripts use relative imports and proper path resolution
- Project root is automatically detected using `Path(__file__).parent.parent`
- No hardcoded paths - fully portable across environments
- Import issues resolved through proper `sys.path` management

### Project Structure
- **Organized**: Clear separation of concerns across directories
- **Scalable**: Easy to add new models or validation scripts
- **Maintainable**: Consistent structure and naming conventions
- **Documented**: Comprehensive documentation and examples

## üÜò Troubleshooting

### Common Issues
1. **Import Errors**: Ensure you're running scripts from project root
2. **Path Issues**: Use `python -m validations.debug_paths` to check paths
3. **Model Issues**: Use `python -m validations.debug_trainer` to test models
4. **Validation Errors**: Run `python -m validations.validate_restructure` for full check

### Getting Help
- Check validation outputs in `validations/validation_output.txt`
- Run individual validation scripts for specific issues
- Review JSON outputs for detailed results
- Check model artifacts in `models/` directory

---

**Last Updated**: Project restructured with dedicated `validations/` directory and comprehensive documentation.
