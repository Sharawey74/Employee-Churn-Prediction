{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a889d6",
   "metadata": {},
   "source": [
    "# ğŸ”§ Feature Engineering: Preparing Data for Machine Learning\n",
    "\n",
    "Welcome to **Feature Engineering** - one of the most crucial steps in machine learning! ğŸš€\n",
    "\n",
    "## ğŸ¯ What is Feature Engineering?\n",
    "\n",
    "Feature Engineering is like being a **data chef** ğŸ‘¨â€ğŸ³ - you take raw ingredients (original data) and transform them into a delicious meal (model-ready features) that machine learning algorithms can easily digest and learn from.\n",
    "\n",
    "### ğŸŒŸ Why is this so important?\n",
    "- **ğŸ¯ Better Predictions**: Well-engineered features = better model performance\n",
    "- **ğŸ§  Algorithm Friendly**: Makes data easier for algorithms to understand\n",
    "- **ğŸ“Š Information Extraction**: Reveals hidden patterns in the data\n",
    "- **âš¡ Efficiency**: Reduces training time and improves accuracy\n",
    "\n",
    "## ğŸ“š What We'll Learn Today:\n",
    "\n",
    "### ğŸ”„ **Data Preprocessing** \n",
    "- Handle missing values (fill the gaps)\n",
    "- Deal with outliers (unusual values)\n",
    "- Remove duplicates and clean data\n",
    "\n",
    "### ğŸ·ï¸ **Categorical Encoding**\n",
    "- Convert text labels to numbers\n",
    "- One-Hot Encoding, Label Encoding, Target Encoding\n",
    "- Handle high-cardinality categories\n",
    "\n",
    "### ğŸ“ **Feature Scaling** \n",
    "- Standardization vs. Normalization\n",
    "- When and why to scale features\n",
    "- Different scaling techniques\n",
    "\n",
    "### âœ¨ **Feature Creation**\n",
    "- Create new features from existing ones\n",
    "- Polynomial features, interactions\n",
    "- Domain-specific transformations\n",
    "\n",
    "### ğŸ¯ **Feature Selection**\n",
    "- Remove irrelevant or redundant features\n",
    "- Statistical tests and importance scores\n",
    "- Dimensionality reduction\n",
    "\n",
    "### âš–ï¸ **Class Imbalance Handling**\n",
    "- SMOTE (Synthetic Minority Oversampling)\n",
    "- Undersampling and Oversampling\n",
    "- Class weights\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Let's Transform Our Data!\n",
    "\n",
    "By the end of this notebook, you'll have:\n",
    "- âœ… Clean, preprocessed data\n",
    "- âœ… Properly encoded categorical variables  \n",
    "- âœ… Scaled numerical features\n",
    "- âœ… New engineered features\n",
    "- âœ… Balanced target classes\n",
    "- âœ… A dataset ready for machine learning!\n",
    "\n",
    "Let's dive in! ğŸŠâ€â™‚ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74c69c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ IMPORTING LIBRARIES FOR FEATURE ENGINEERING...\n",
      "==================================================\n",
      "\n",
      "ğŸ“ SETTING UP PROJECT PATHS...\n",
      "===================================\n",
      "ğŸ“‚ Project root: c:\\Users\\DELL\\Desktop\\AI-Project\\AI-Project\n",
      "ğŸ“‚ Source code: c:\\Users\\DELL\\Desktop\\AI-Project\\AI-Project\\src\n",
      "ğŸ“‚ Current notebook: c:\\Users\\DELL\\Desktop\\AI-Project\\AI-Project\\notebooks\n",
      "\n",
      "ğŸ¯ SETTING UP TARGET VARIABLE...\n",
      "===================================\n",
      "ğŸ² Random state set to: 42 (for reproducible results)\n",
      "âœ… Setup complete! Ready to load and engineer features.\n",
      "\n",
      "ğŸ“Š PREPARING FOR DATA LOADING...\n",
      "===================================\n",
      "Next, we'll load our cleaned data from the previous EDA analysis.\n",
      "We'll use the insights from EDA to guide our feature engineering decisions.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Step 1: Import All Required Libraries\n",
    "print(\"ğŸ“¦ IMPORTING LIBRARIES FOR FEATURE ENGINEERING...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Core data manipulation and analysis\n",
    "import pandas as pd              # Data manipulation and analysis\n",
    "import numpy as np               # Numerical computing\n",
    "import matplotlib.pyplot as plt  # Data visualization\n",
    "import seaborn as sns            # Statistical data visualization\n",
    "import warnings                  # Handle warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up nice-looking plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split     # Split data into train/test\n",
    "from sklearn.preprocessing import StandardScaler         # Scale features to standard distribution\n",
    "from sklearn.preprocessing import MinMaxScaler          # Scale features to 0-1 range\n",
    "from sklearn.preprocessing import LabelEncoder          # Convert categories to numbers\n",
    "from sklearn.preprocessing import OneHotEncoder         # Create binary columns for categories\n",
    "from sklearn.feature_selection import SelectKBest       # Select best features\n",
    "from sklearn.feature_selection import chi2, f_classif   # Statistical tests for feature selection\n",
    "\n",
    "# Handle class imbalance\n",
    "from imblearn.over_sampling import SMOTE                # Synthetic Minority Oversampling\n",
    "from collections import Counter                         # Count class frequencies\n",
    "\n",
    "# File path handling\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# ğŸ“ Step 2: Set up paths to our project\n",
    "print(\"\\nğŸ“ SETTING UP PROJECT PATHS...\")\n",
    "print(\"=\"*35)\n",
    "\n",
    "# Get the current notebook directory and find project root\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent\n",
    "\n",
    "# Add src directory to Python path so we can import our modules\n",
    "src_path = project_root / 'src'\n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "print(f\"ğŸ“‚ Project root: {project_root}\")\n",
    "print(f\"ğŸ“‚ Source code: {src_path}\")\n",
    "print(f\"ğŸ“‚ Current notebook: {current_dir}\")\n",
    "\n",
    "# ğŸ¯ Step 3: Define what we're trying to predict\n",
    "print(\"\\nğŸ¯ SETTING UP TARGET VARIABLE...\")\n",
    "print(\"=\"*35)\n",
    "\n",
    "# This will be updated once we load and examine the data\n",
    "TARGET_COLUMN = None  # We'll identify this from the data\n",
    "RANDOM_STATE = 42     # For reproducible results\n",
    "\n",
    "print(f\"ğŸ² Random state set to: {RANDOM_STATE} (for reproducible results)\")\n",
    "print(\"âœ… Setup complete! Ready to load and engineer features.\")\n",
    "\n",
    "# ğŸ“Š Step 4: Prepare for data loading\n",
    "print(\"\\nğŸ“Š PREPARING FOR DATA LOADING...\")\n",
    "print(\"=\"*35)\n",
    "print(\"Next, we'll load our cleaned data from the previous EDA analysis.\")\n",
    "print(\"We'll use the insights from EDA to guide our feature engineering decisions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ddf24",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 1: Load and Examine Our Data\n",
    "\n",
    "Let's start by loading our dataset and taking a quick look at what we're working with. We'll use the insights from our previous EDA to guide our feature engineering decisions.\n",
    "\n",
    "### ğŸ” What we'll check:\n",
    "- **ğŸ“Š Data shape and types**: Understand our starting point\n",
    "- **ğŸ¯ Target variable**: Identify what we're predicting  \n",
    "- **ğŸ“‹ Feature types**: Separate numerical and categorical features\n",
    "- **â“ Data quality**: Check for issues that need fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83383279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ LOADING DATASET...\n",
      "=========================\n",
      "ğŸ“‚ Found data file: employee_data.csv\n",
      "âœ… Successfully loaded: employee_data.csv\n",
      "ğŸ“Š Dataset shape: 11,582 rows Ã— 10 columns\n",
      "\n",
      "ğŸ” QUICK DATA EXAMINATION:\n",
      "==============================\n",
      "ğŸ“‹ Column names:\n",
      "   1. satisfaction_level\n",
      "   2. last_evaluation\n",
      "   3. number_project\n",
      "   4. average_montly_hours\n",
      "   5. time_spend_company\n",
      "   6. Work_accident\n",
      "   7. quit\n",
      "   8. promotion_last_5years\n",
      "   9. department\n",
      "  10. salary\n",
      "\n",
      "ğŸ“Š Data types:\n",
      "  â€¢ satisfaction_level   â†’ float64\n",
      "  â€¢ last_evaluation      â†’ float64\n",
      "  â€¢ number_project       â†’ int64\n",
      "  â€¢ average_montly_hours â†’ int64\n",
      "  â€¢ time_spend_company   â†’ int64\n",
      "  â€¢ Work_accident        â†’ int64\n",
      "  â€¢ quit                 â†’ int64\n",
      "  â€¢ promotion_last_5years â†’ float64\n",
      "  â€¢ department           â†’ object\n",
      "  â€¢ salary               â†’ object\n",
      "\n",
      "â“ Missing values:\n",
      "  â€¢ promotion_last_5years â†’ 1 missing\n",
      "  â€¢ department           â†’ 1 missing\n",
      "  â€¢ salary               â†’ 1 missing\n",
      "\n",
      "ğŸ”¢ Basic statistics:\n",
      "  â€¢ Memory usage: 2.09 MB\n",
      "  â€¢ Duplicate rows: 9\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“ Step 1: Load our dataset\n",
    "print(\"ğŸ“ LOADING DATASET...\")\n",
    "print(\"=\"*25)\n",
    "\n",
    "# Try to load from the data directory\n",
    "data_path = project_root / 'data' / 'raw'\n",
    "possible_files = ['employee_data.csv', 'employees.csv', 'hr_data.csv', 'data.csv']\n",
    "\n",
    "df = None\n",
    "loaded_file = None\n",
    "\n",
    "# Look for common employee dataset filenames\n",
    "for filename in possible_files:\n",
    "    file_path = data_path / filename\n",
    "    if file_path.exists():\n",
    "        print(f\"ğŸ“‚ Found data file: {filename}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        loaded_file = filename\n",
    "        break\n",
    "\n",
    "# If not found in data/raw, try other locations\n",
    "if df is None:\n",
    "    # Try data directory root\n",
    "    for filename in possible_files:\n",
    "        file_path = project_root / 'data' / filename\n",
    "        if file_path.exists():\n",
    "            print(f\"ğŸ“‚ Found data file: {filename}\")\n",
    "            df = pd.read_csv(file_path)\n",
    "            loaded_file = filename\n",
    "            break\n",
    "\n",
    "# If still not found, try project root\n",
    "if df is None:\n",
    "    for filename in possible_files:\n",
    "        file_path = project_root / filename\n",
    "        if file_path.exists():\n",
    "            print(f\"ğŸ“‚ Found data file: {filename}\")\n",
    "            df = pd.read_csv(file_path)\n",
    "            loaded_file = filename\n",
    "            break\n",
    "\n",
    "# Check if we successfully loaded data\n",
    "if df is not None:\n",
    "    print(f\"âœ… Successfully loaded: {loaded_file}\")\n",
    "    print(f\"ğŸ“Š Dataset shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "else:\n",
    "    print(\"âŒ No dataset found. Please ensure you have a CSV file in the data directory.\")\n",
    "    print(\"ğŸ“ Expected files: employee_data.csv, employees.csv, hr_data.csv, or data.csv\")\n",
    "\n",
    "# ğŸ” Step 2: Quick data examination\n",
    "if df is not None:\n",
    "    print(f\"\\nğŸ” QUICK DATA EXAMINATION:\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    print(f\"ğŸ“‹ Column names:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:2}. {col}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Data types:\")\n",
    "    for col, dtype in df.dtypes.items():\n",
    "        print(f\"  â€¢ {col:20} â†’ {dtype}\")\n",
    "    \n",
    "    print(f\"\\nâ“ Missing values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() == 0:\n",
    "        print(\"  âœ… No missing values found!\")\n",
    "    else:\n",
    "        for col, count in missing[missing > 0].items():\n",
    "            print(f\"  â€¢ {col:20} â†’ {count:,} missing\")\n",
    "    \n",
    "    print(f\"\\nğŸ”¢ Basic statistics:\")\n",
    "    print(f\"  â€¢ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(f\"  â€¢ Duplicate rows: {df.duplicated().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018eec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ IDENTIFYING TARGET VARIABLE...\n",
      "===================================\n",
      "âœ… Target variable identified: 'quit'\n",
      "\n",
      "ğŸ“Š Target distribution:\n",
      "  â€¢ 0: 9,582 (82.7%)\n",
      "  â€¢ 1: 2,000 (17.3%)\n",
      "\n",
      "ğŸ“‹ SEPARATING FEATURE TYPES...\n",
      "==============================\n",
      "ğŸ”¢ Numerical features (7):\n",
      "   1. satisfaction_level   â†’ 92 unique values\n",
      "   2. last_evaluation      â†’ 65 unique values\n",
      "   3. number_project       â†’ 6 unique values\n",
      "   4. average_montly_hours â†’ 215 unique values\n",
      "   5. time_spend_company   â†’ 8 unique values\n",
      "   6. Work_accident        â†’ 2 unique values\n",
      "   7. promotion_last_5years â†’ 2 unique values\n",
      "\n",
      "ğŸ·ï¸ Categorical features (2):\n",
      "   1. department           â†’ 10 unique categories\n",
      "   2. salary               â†’ 3 unique categories\n",
      "\n",
      "ğŸ¤” Potential categorical (currently numerical):\n",
      "  â€¢ number_project       â†’ [2 5 7 6 4]...\n",
      "    ğŸ’­ Consider: Should this be treated as categorical?\n",
      "  â€¢ time_spend_company   â†’ [3 6 4 5 2]...\n",
      "    ğŸ’­ Consider: Should this be treated as categorical?\n",
      "  â€¢ Work_accident        â†’ [0 1]...\n",
      "    ğŸ’­ Consider: Should this be treated as categorical?\n",
      "\n",
      "ğŸ“Š Summary:\n",
      "  â€¢ Total features: 9\n",
      "  â€¢ Numerical: 7\n",
      "  â€¢ Categorical: 2\n",
      "  â€¢ Target: quit\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ Step 3: Identify target variable and feature types\n",
    "if df is not None:\n",
    "    print(\"\\nğŸ¯ IDENTIFYING TARGET VARIABLE...\")\n",
    "    print(\"=\"*35)\n",
    "    \n",
    "    # Common target variable names for employee attrition\n",
    "    target_candidates = ['Attrition', 'attrition', 'Left', 'left', 'Turnover', 'turnover', \n",
    "                        'Quit', 'quit', 'Exit', 'exit', 'Churn', 'churn']\n",
    "    \n",
    "    # Look for target variable\n",
    "    target_col = None\n",
    "    for col in df.columns:\n",
    "        if col in target_candidates or any(candidate.lower() in col.lower() for candidate in target_candidates):\n",
    "            target_col = col\n",
    "            break\n",
    "    \n",
    "    # If not found by name, look for binary variables (likely targets)\n",
    "    if target_col is None:\n",
    "        binary_cols = [col for col in df.columns if df[col].nunique() == 2]\n",
    "        if binary_cols:\n",
    "            print(\"ğŸ” Binary columns found (potential targets):\")\n",
    "            for i, col in enumerate(binary_cols, 1):\n",
    "                values = df[col].unique()\n",
    "                print(f\"  {i}. {col}: {values}\")\n",
    "            \n",
    "            # Assume first binary column is target for now\n",
    "            target_col = binary_cols[0]\n",
    "            print(f\"\\nğŸ¯ Assuming target variable: '{target_col}'\")\n",
    "    \n",
    "    if target_col:\n",
    "        TARGET_COLUMN = target_col\n",
    "        print(f\"âœ… Target variable identified: '{TARGET_COLUMN}'\")\n",
    "        \n",
    "        # Show target distribution\n",
    "        target_counts = df[TARGET_COLUMN].value_counts()\n",
    "        print(f\"\\nğŸ“Š Target distribution:\")\n",
    "        for value, count in target_counts.items():\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"  â€¢ {value}: {count:,} ({percentage:.1f}%)\")\n",
    "    else:\n",
    "        print(\"â“ Target variable not found automatically.\")\n",
    "        print(\"ğŸ’¡ You may need to specify it manually later.\")\n",
    "    \n",
    "    # ğŸ“‹ Step 4: Separate feature types\n",
    "    print(f\"\\nğŸ“‹ SEPARATING FEATURE TYPES...\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # Get all columns except target\n",
    "    feature_columns = [col for col in df.columns if col != TARGET_COLUMN]\n",
    "    \n",
    "    # Identify numerical features (numbers we can do math with)\n",
    "    numerical_features = df[feature_columns].select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Identify categorical features (text or categories)\n",
    "    categorical_features = df[feature_columns].select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Also check for numerical columns that should be treated as categorical\n",
    "    # (like ID numbers, codes with few unique values)\n",
    "    potential_categorical = []\n",
    "    for col in numerical_features:\n",
    "        unique_count = df[col].nunique()\n",
    "        # If less than 10 unique values and they're integers, might be categorical\n",
    "        if unique_count < 10 and df[col].dtype in ['int64', 'int32']:\n",
    "            potential_categorical.append(col)\n",
    "    \n",
    "    print(f\"ğŸ”¢ Numerical features ({len(numerical_features)}):\")\n",
    "    for i, col in enumerate(numerical_features, 1):\n",
    "        unique_count = df[col].nunique()\n",
    "        print(f\"  {i:2}. {col:20} â†’ {unique_count:,} unique values\")\n",
    "    \n",
    "    print(f\"\\nğŸ·ï¸ Categorical features ({len(categorical_features)}):\")\n",
    "    for i, col in enumerate(categorical_features, 1):\n",
    "        unique_count = df[col].nunique()\n",
    "        print(f\"  {i:2}. {col:20} â†’ {unique_count:,} unique categories\")\n",
    "    \n",
    "    if potential_categorical:\n",
    "        print(f\"\\nğŸ¤” Potential categorical (currently numerical):\")\n",
    "        for col in potential_categorical:\n",
    "            values = df[col].unique()[:5]  # Show first 5 values\n",
    "            print(f\"  â€¢ {col:20} â†’ {values}...\")\n",
    "            print(f\"    ğŸ’­ Consider: Should this be treated as categorical?\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Summary:\")\n",
    "    print(f\"  â€¢ Total features: {len(feature_columns)}\")\n",
    "    print(f\"  â€¢ Numerical: {len(numerical_features)}\")\n",
    "    print(f\"  â€¢ Categorical: {len(categorical_features)}\")\n",
    "    if TARGET_COLUMN:\n",
    "        print(f\"  â€¢ Target: {TARGET_COLUMN}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Cannot proceed without data. Please load dataset first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369d7281",
   "metadata": {},
   "source": [
    "## ğŸ”„ Step 2: Data Preprocessing - Cleaning Our Data\n",
    "\n",
    "Before we can engineer features, we need to clean our data! Think of this as **washing the vegetables** ğŸ¥¬ before cooking - it's essential for a good final result.\n",
    "\n",
    "### ğŸ§¹ What we'll clean:\n",
    "- **âŒ Missing values**: Fill gaps in our data\n",
    "- **ğŸ”„ Duplicates**: Remove identical rows\n",
    "- **ğŸ“Š Outliers**: Handle extreme values that might confuse our model\n",
    "- **ğŸ”§ Data types**: Make sure everything is in the right format\n",
    "\n",
    "### ğŸ¯ Why this matters:\n",
    "- **Clean data = Better models** ğŸ“ˆ\n",
    "- **Prevents errors** during training âŒ\n",
    "- **Improves accuracy** and reliability âœ…\n",
    "- **Makes feature engineering** more effective ğŸ”§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416cd465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” HANDLING MISSING VALUES...\n",
      "==============================\n",
      "ğŸ“Š Missing values analysis:\n",
      "  â€¢ promotion_last_5years â†’ 1 missing (0.01%)\n",
      "  â€¢ department           â†’ 1 missing (0.01%)\n",
      "  â€¢ salary               â†’ 1 missing (0.01%)\n",
      "\n",
      "ğŸ”§ FIXING MISSING VALUES...\n",
      "=========================\n",
      "\n",
      "ğŸ”§ Fixing promotion_last_5years (1 missing, 0.0%):\n",
      "  âœ… Filled with median value: 0.0\n",
      "\n",
      "ğŸ”§ Fixing department (1 missing, 0.0%):\n",
      "  âœ… Filled with most common value: 'sales'\n",
      "\n",
      "ğŸ”§ Fixing salary (1 missing, 0.0%):\n",
      "  âœ… Filled with most common value: 'low'\n",
      "\n",
      "âœ… All missing values fixed successfully!\n",
      "\n",
      "ğŸ”„ HANDLING DUPLICATE ROWS...\n",
      "===========================\n",
      "ğŸ“Š Found 9 duplicate rows\n",
      "ğŸ”§ Removing duplicates...\n",
      "  âœ… Removed 9 duplicate rows\n",
      "  ğŸ“Š Dataset size: 11,582 â†’ 11,573 rows\n",
      "\n",
      "ğŸ“Š CLEANED DATASET SUMMARY:\n",
      "==============================\n",
      "  â€¢ Final shape: 11,573 rows Ã— 10 columns\n",
      "  â€¢ Missing values: 0\n",
      "  â€¢ Duplicate rows: 0\n",
      "  â€¢ Memory usage: 2.17 MB\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Step 1: Handle Missing Values\n",
    "if df is not None:\n",
    "    print(\"ğŸ” HANDLING MISSING VALUES...\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percentage = (missing_values / len(df)) * 100\n",
    "    \n",
    "    print(\"ğŸ“Š Missing values analysis:\")\n",
    "    has_missing = False\n",
    "    for col in df.columns:\n",
    "        missing_count = missing_values[col]\n",
    "        missing_pct = missing_percentage[col]\n",
    "        \n",
    "        if missing_count > 0:\n",
    "            has_missing = True\n",
    "            print(f\"  â€¢ {col:20} â†’ {missing_count:,} missing ({missing_pct:.2f}%)\")\n",
    "    \n",
    "    if not has_missing:\n",
    "        print(\"  âœ… No missing values found! Data is complete.\")\n",
    "    else:\n",
    "        print(f\"\\nğŸ”§ FIXING MISSING VALUES...\")\n",
    "        print(\"=\"*25)\n",
    "        \n",
    "        # Strategy for handling missing values:\n",
    "        # 1. Numerical: Fill with median (robust to outliers)\n",
    "        # 2. Categorical: Fill with mode (most common value) or 'Unknown'\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if missing_values[col] > 0:\n",
    "                missing_count = missing_values[col]\n",
    "                missing_pct = missing_percentage[col]\n",
    "                \n",
    "                print(f\"\\nğŸ”§ Fixing {col} ({missing_count:,} missing, {missing_pct:.1f}%):\")\n",
    "                \n",
    "                if col in numerical_features:\n",
    "                    # For numerical: use median (more robust than mean)\n",
    "                    median_value = df[col].median()\n",
    "                    df[col].fillna(median_value, inplace=True)\n",
    "                    print(f\"  âœ… Filled with median value: {median_value}\")\n",
    "                    \n",
    "                elif col in categorical_features:\n",
    "                    # For categorical: use mode (most common) or 'Unknown'\n",
    "                    if df[col].mode().empty:\n",
    "                        fill_value = 'Unknown'\n",
    "                    else:\n",
    "                        fill_value = df[col].mode()[0]\n",
    "                    \n",
    "                    df[col].fillna(fill_value, inplace=True)\n",
    "                    print(f\"  âœ… Filled with most common value: '{fill_value}'\")\n",
    "        \n",
    "        # Verify all missing values are fixed\n",
    "        remaining_missing = df.isnull().sum().sum()\n",
    "        if remaining_missing == 0:\n",
    "            print(f\"\\nâœ… All missing values fixed successfully!\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸ {remaining_missing} missing values remain\")\n",
    "    \n",
    "    # ğŸ”„ Step 2: Handle Duplicate Rows\n",
    "    print(f\"\\nğŸ”„ HANDLING DUPLICATE ROWS...\")\n",
    "    print(\"=\"*27)\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"ğŸ“Š Found {duplicate_count:,} duplicate rows\")\n",
    "    \n",
    "    if duplicate_count > 0:\n",
    "        print(f\"ğŸ”§ Removing duplicates...\")\n",
    "        \n",
    "        # Keep first occurrence, remove duplicates\n",
    "        original_size = len(df)\n",
    "        df = df.drop_duplicates(keep='first')\n",
    "        new_size = len(df)\n",
    "        removed = original_size - new_size\n",
    "        \n",
    "        print(f\"  âœ… Removed {removed:,} duplicate rows\")\n",
    "        print(f\"  ğŸ“Š Dataset size: {original_size:,} â†’ {new_size:,} rows\")\n",
    "    else:\n",
    "        print(\"  âœ… No duplicate rows found!\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š CLEANED DATASET SUMMARY:\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"  â€¢ Final shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "    print(f\"  â€¢ Missing values: {df.isnull().sum().sum()}\")\n",
    "    print(f\"  â€¢ Duplicate rows: {df.duplicated().sum()}\")\n",
    "    print(f\"  â€¢ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ No data available for preprocessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60174a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š HANDLING OUTLIERS...\n",
      "====================\n",
      "ğŸ” What are outliers?\n",
      "Outliers are data points that are significantly different from others.\n",
      "Example: If most employees earn $30k-80k, someone earning $500k is an outlier.\n",
      "\n",
      "ğŸ“ Using IQR (Interquartile Range) method:\n",
      "â€¢ Q1 = 25th percentile (25% of data below this)\n",
      "â€¢ Q3 = 75th percentile (75% of data below this)\n",
      "â€¢ IQR = Q3 - Q1 (middle 50% range)\n",
      "â€¢ Outliers: values below Q1-1.5Ã—IQR or above Q3+1.5Ã—IQR\n",
      "\n",
      "ğŸ” Analyzing satisfaction_level:\n",
      "  â€¢ Normal range: -0.03 to 1.33\n",
      "  â€¢ Outliers found: 0 (0.00%)\n",
      "  âœ… No outliers detected\n",
      "\n",
      "ğŸ” Analyzing last_evaluation:\n",
      "  â€¢ Normal range: 0.12 to 1.32\n",
      "  â€¢ Outliers found: 0 (0.00%)\n",
      "  âœ… No outliers detected\n",
      "\n",
      "ğŸ” Analyzing number_project:\n",
      "  â€¢ Normal range: 0.00 to 8.00\n",
      "  â€¢ Outliers found: 0 (0.00%)\n",
      "  âœ… No outliers detected\n",
      "\n",
      "ğŸ” Analyzing average_montly_hours:\n",
      "  â€¢ Normal range: 28.00 to 372.00\n",
      "  â€¢ Outliers found: 0 (0.00%)\n",
      "  âœ… No outliers detected\n",
      "\n",
      "ğŸ” Analyzing time_spend_company:\n",
      "  â€¢ Normal range: 1.50 to 5.50\n",
      "  â€¢ Outliers found: 663 (5.73%)\n",
      "  â€¢ Outlier range: 6.00 to 10.00\n",
      "\n",
      "ğŸ” Analyzing Work_accident:\n",
      "  â€¢ Normal range: 0.00 to 0.00\n",
      "  â€¢ Outliers found: 1,768 (15.28%)\n",
      "  â€¢ Outlier range: 1.00 to 1.00\n",
      "\n",
      "ğŸ” Analyzing promotion_last_5years:\n",
      "  â€¢ Normal range: 0.00 to 0.00\n",
      "  â€¢ Outliers found: 160 (1.38%)\n",
      "  â€¢ Outlier range: 1.00 to 1.00\n",
      "\n",
      "ğŸ”§ OUTLIER HANDLING STRATEGY:\n",
      "==============================\n",
      "ğŸ“Š time_spend_company: 663 outliers (5.7%)\n",
      "  ğŸ”§ Capping outliers to boundary values (winsorization)\n",
      "  âœ… Capped 663 outliers\n",
      "\n",
      "ğŸ“Š Work_accident: 1,768 outliers (15.3%)\n",
      "  ğŸ¤” High outlier percentage - keeping all values\n",
      "  ğŸ’¡ These might represent legitimate data variation\n",
      "\n",
      "ğŸ“Š promotion_last_5years: 160 outliers (1.4%)\n",
      "  ğŸ—‘ï¸ Removing outlier rows (small percentage)\n",
      "  âœ… Removed 160 rows with outliers\n",
      "\n",
      "ğŸ“Š OUTLIER HANDLING SUMMARY:\n",
      "  â€¢ Total outliers handled: 823\n",
      "  â€¢ Final dataset size: 11,413 rows\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š Step 3: Handle Outliers (Extreme Values)\n",
    "if df is not None and len(numerical_features) > 0:\n",
    "    print(\"ğŸ“Š HANDLING OUTLIERS...\")\n",
    "    print(\"=\"*20)\n",
    "    \n",
    "    print(\"ğŸ” What are outliers?\")\n",
    "    print(\"Outliers are data points that are significantly different from others.\")\n",
    "    print(\"Example: If most employees earn $30k-80k, someone earning $500k is an outlier.\")\n",
    "    print()\n",
    "    \n",
    "    # We'll use the IQR (Interquartile Range) method to detect outliers\n",
    "    print(\"ğŸ“ Using IQR (Interquartile Range) method:\")\n",
    "    print(\"â€¢ Q1 = 25th percentile (25% of data below this)\")\n",
    "    print(\"â€¢ Q3 = 75th percentile (75% of data below this)\")\n",
    "    print(\"â€¢ IQR = Q3 - Q1 (middle 50% range)\")\n",
    "    print(\"â€¢ Outliers: values below Q1-1.5Ã—IQR or above Q3+1.5Ã—IQR\")\n",
    "    print()\n",
    "    \n",
    "    outlier_info = {}\n",
    "    \n",
    "    for col in numerical_features:\n",
    "        print(f\"ğŸ” Analyzing {col}:\")\n",
    "        \n",
    "        # Calculate IQR boundaries\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define outlier boundaries\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Find outliers\n",
    "        outliers_mask = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "        outliers_count = outliers_mask.sum()\n",
    "        outliers_percentage = (outliers_count / len(df)) * 100\n",
    "        \n",
    "        print(f\"  â€¢ Normal range: {lower_bound:.2f} to {upper_bound:.2f}\")\n",
    "        print(f\"  â€¢ Outliers found: {outliers_count:,} ({outliers_percentage:.2f}%)\")\n",
    "        \n",
    "        if outliers_count > 0:\n",
    "            outlier_values = df[outliers_mask][col]\n",
    "            print(f\"  â€¢ Outlier range: {outlier_values.min():.2f} to {outlier_values.max():.2f}\")\n",
    "            \n",
    "            # Store outlier info for decision making\n",
    "            outlier_info[col] = {\n",
    "                'count': outliers_count,\n",
    "                'percentage': outliers_percentage,\n",
    "                'lower_bound': lower_bound,\n",
    "                'upper_bound': upper_bound,\n",
    "                'mask': outliers_mask\n",
    "            }\n",
    "        else:\n",
    "            print(f\"  âœ… No outliers detected\")\n",
    "        print()\n",
    "    \n",
    "    # ğŸ”§ Decide how to handle outliers\n",
    "    print(\"ğŸ”§ OUTLIER HANDLING STRATEGY:\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    outliers_handled = 0\n",
    "    \n",
    "    for col, info in outlier_info.items():\n",
    "        outlier_percentage = info['percentage']\n",
    "        \n",
    "        print(f\"ğŸ“Š {col}: {info['count']:,} outliers ({outlier_percentage:.1f}%)\")\n",
    "        \n",
    "        if outlier_percentage > 10:\n",
    "            # Too many outliers - might be legitimate data variation\n",
    "            print(f\"  ğŸ¤” High outlier percentage - keeping all values\")\n",
    "            print(f\"  ğŸ’¡ These might represent legitimate data variation\")\n",
    "            \n",
    "        elif outlier_percentage > 5:\n",
    "            # Moderate outliers - cap them (winsorization)\n",
    "            print(f\"  ğŸ”§ Capping outliers to boundary values (winsorization)\")\n",
    "            \n",
    "            # Cap outliers to the boundary values\n",
    "            df.loc[df[col] < info['lower_bound'], col] = info['lower_bound']\n",
    "            df.loc[df[col] > info['upper_bound'], col] = info['upper_bound']\n",
    "            \n",
    "            outliers_handled += info['count']\n",
    "            print(f\"  âœ… Capped {info['count']:,} outliers\")\n",
    "            \n",
    "        elif outlier_percentage > 0:\n",
    "            # Few outliers - remove them\n",
    "            print(f\"  ğŸ—‘ï¸ Removing outlier rows (small percentage)\")\n",
    "            \n",
    "            # Remove rows with outliers in this column\n",
    "            original_size = len(df)\n",
    "            df = df[~info['mask']]\n",
    "            new_size = len(df)\n",
    "            removed = original_size - new_size\n",
    "            \n",
    "            outliers_handled += removed\n",
    "            print(f\"  âœ… Removed {removed:,} rows with outliers\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    if outliers_handled > 0:\n",
    "        print(f\"ğŸ“Š OUTLIER HANDLING SUMMARY:\")\n",
    "        print(f\"  â€¢ Total outliers handled: {outliers_handled:,}\")\n",
    "        print(f\"  â€¢ Final dataset size: {len(df):,} rows\")\n",
    "    else:\n",
    "        print(\"âœ… No outlier handling needed - data looks good!\")\n",
    "\n",
    "else:\n",
    "    if df is None:\n",
    "        print(\"âš ï¸ No data available for outlier analysis.\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸ No numerical features found - skipping outlier analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86380d98",
   "metadata": {},
   "source": [
    "## ğŸ·ï¸ Step 3: Categorical Encoding - Converting Text to Numbers\n",
    "\n",
    "Machine learning algorithms can only work with numbers, not text! ğŸ”¢ So we need to convert our categorical features (like \"Sales\", \"Engineering\", \"HR\") into numbers that algorithms can understand.\n",
    "\n",
    "### ğŸ”„ Encoding Methods We'll Use:\n",
    "\n",
    "#### 1ï¸âƒ£ **Label Encoding** \n",
    "- **What**: Assigns each category a number (0, 1, 2, ...)\n",
    "- **When**: For ordinal data (categories with natural order)\n",
    "- **Example**: Education â†’ High School=0, Bachelor's=1, Master's=2, PhD=3\n",
    "\n",
    "#### 2ï¸âƒ£ **One-Hot Encoding**\n",
    "- **What**: Creates binary columns (0 or 1) for each category\n",
    "- **When**: For nominal data (no natural order)\n",
    "- **Example**: Department â†’ Dept_Sales=1, Dept_HR=0, Dept_IT=0\n",
    "\n",
    "#### 3ï¸âƒ£ **Target Encoding** \n",
    "- **What**: Replaces categories with target variable statistics\n",
    "- **When**: High-cardinality features (many categories)\n",
    "- **Example**: Job_Role â†’ average attrition rate for each role\n",
    "\n",
    "### ğŸ¯ Why This Matters:\n",
    "- **ğŸ¤– Algorithm Compatibility**: Makes data readable by ML models\n",
    "- **ğŸ“Š Pattern Recognition**: Helps models find relationships\n",
    "- **âš¡ Performance**: Proper encoding improves model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f7ac736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ·ï¸ ANALYZING CATEGORICAL FEATURES...\n",
      "======================================\n",
      "ğŸ“Š department:\n",
      "  â€¢ Unique categories: 10\n",
      "  â€¢ Categories: ['sales' 'accounting' 'hr' 'technical' 'support']...\n",
      "  ğŸ¯ Strategy: One-Hot Encoding (Nominal)\n",
      "\n",
      "ğŸ“Š salary:\n",
      "  â€¢ Unique categories: 3\n",
      "  â€¢ Categories: ['low' 'medium' 'high']\n",
      "  ğŸ¯ Strategy: One-Hot Encoding (Few categories)\n",
      "\n",
      "ğŸ”§ APPLYING ENCODING STRATEGIES...\n",
      "===================================\n",
      "ğŸ”§ Encoding department using ONEHOT...\n",
      "  ğŸ“‹ Created 10 binary columns:\n",
      "    â€¢ department_IT\n",
      "    â€¢ department_RandD\n",
      "    â€¢ department_accounting\n",
      "    â€¢ department_hr\n",
      "    â€¢ department_management\n",
      "    â€¢ department_marketing\n",
      "    â€¢ department_product_mng\n",
      "    â€¢ department_sales\n",
      "    â€¢ department_support\n",
      "    â€¢ department_technical\n",
      "  âœ… Encoded successfully!\n",
      "\n",
      "ğŸ”§ Encoding salary using ONEHOT...\n",
      "  ğŸ“‹ Created 3 binary columns:\n",
      "    â€¢ salary_high\n",
      "    â€¢ salary_low\n",
      "    â€¢ salary_medium\n",
      "  âœ… Encoded successfully!\n",
      "\n",
      "ğŸ—‘ï¸ CLEANING UP ORIGINAL CATEGORICAL COLUMNS...\n",
      "=============================================\n",
      "ğŸ“‹ Removing original categorical columns:\n",
      "  â€¢ department\n",
      "  â€¢ salary\n",
      "\n",
      "ğŸ“Š ENCODING SUMMARY:\n",
      "====================\n",
      "  â€¢ Original categorical columns: 2\n",
      "  â€¢ New encoded features: 13\n",
      "  â€¢ Total columns now: 21\n",
      "  â€¢ Numerical features: 7\n",
      "  â€¢ Encoded features: 13\n",
      "  â€¢ Total features: 20\n"
     ]
    }
   ],
   "source": [
    "# ğŸ·ï¸ Step 1: Analyze categorical features for encoding strategy\n",
    "if df is not None and len(categorical_features) > 0:\n",
    "    print(\"ğŸ·ï¸ ANALYZING CATEGORICAL FEATURES...\")\n",
    "    print(\"=\"*38)\n",
    "    \n",
    "    encoding_strategy = {}\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        unique_count = df[col].nunique()\n",
    "        values = df[col].unique()\n",
    "        \n",
    "        print(f\"ğŸ“Š {col}:\")\n",
    "        print(f\"  â€¢ Unique categories: {unique_count}\")\n",
    "        print(f\"  â€¢ Categories: {values[:5]}{'...' if len(values) > 5 else ''}\")\n",
    "        \n",
    "        # Decide encoding strategy based on characteristics\n",
    "        if unique_count == 2:\n",
    "            # Binary categorical - use label encoding\n",
    "            strategy = \"Label Encoding (Binary)\"\n",
    "            encoding_strategy[col] = \"label\"\n",
    "            \n",
    "        elif unique_count <= 5:\n",
    "            # Few categories - use one-hot encoding\n",
    "            strategy = \"One-Hot Encoding (Few categories)\"\n",
    "            encoding_strategy[col] = \"onehot\"\n",
    "            \n",
    "        elif unique_count <= 20:\n",
    "            # Moderate categories - check if ordinal or use one-hot\n",
    "            # Check if there's natural ordering (common ordinal patterns)\n",
    "            ordinal_patterns = ['low', 'medium', 'high', 'small', 'large', \n",
    "                              'junior', 'senior', 'beginner', 'intermediate', 'advanced']\n",
    "            \n",
    "            is_ordinal = any(pattern in str(values).lower() for pattern in ordinal_patterns)\n",
    "            \n",
    "            if is_ordinal:\n",
    "                strategy = \"Label Encoding (Ordinal detected)\"\n",
    "                encoding_strategy[col] = \"label\"\n",
    "            else:\n",
    "                strategy = \"One-Hot Encoding (Nominal)\"\n",
    "                encoding_strategy[col] = \"onehot\"\n",
    "                \n",
    "        else:\n",
    "            # Many categories - use target encoding\n",
    "            strategy = \"Target Encoding (High cardinality)\"\n",
    "            encoding_strategy[col] = \"target\"\n",
    "        \n",
    "        print(f\"  ğŸ¯ Strategy: {strategy}\")\n",
    "        print()\n",
    "    \n",
    "    # ğŸ”§ Step 2: Apply encoding strategies\n",
    "    print(\"ğŸ”§ APPLYING ENCODING STRATEGIES...\")\n",
    "    print(\"=\"*35)\n",
    "    \n",
    "    # Store original columns for reference\n",
    "    original_columns = df.columns.tolist()\n",
    "    encoded_features = []\n",
    "    \n",
    "    # Keep track of encoders for future use\n",
    "    label_encoders = {}\n",
    "    onehot_encoders = {}\n",
    "    \n",
    "    for col, strategy in encoding_strategy.items():\n",
    "        print(f\"ğŸ”§ Encoding {col} using {strategy.upper()}...\")\n",
    "        \n",
    "        if strategy == \"label\":\n",
    "            # Label Encoding: Assign numbers to categories\n",
    "            le = LabelEncoder()\n",
    "            df[f'{col}_encoded'] = le.fit_transform(df[col])\n",
    "            label_encoders[col] = le\n",
    "            \n",
    "            # Show mapping\n",
    "            mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            print(f\"  ğŸ“‹ Mapping: {mapping}\")\n",
    "            encoded_features.append(f'{col}_encoded')\n",
    "            \n",
    "        elif strategy == \"onehot\":\n",
    "            # One-Hot Encoding: Create binary columns\n",
    "            encoded_cols = pd.get_dummies(df[col], prefix=col, prefix_sep='_')\n",
    "            \n",
    "            # Add to dataframe\n",
    "            df = pd.concat([df, encoded_cols], axis=1)\n",
    "            \n",
    "            print(f\"  ğŸ“‹ Created {len(encoded_cols.columns)} binary columns:\")\n",
    "            for new_col in encoded_cols.columns:\n",
    "                print(f\"    â€¢ {new_col}\")\n",
    "                encoded_features.append(new_col)\n",
    "                \n",
    "        elif strategy == \"target\" and TARGET_COLUMN:\n",
    "            # Target Encoding: Replace with target statistics\n",
    "            target_mean = df.groupby(col)[TARGET_COLUMN].transform('mean')\n",
    "            df[f'{col}_target_encoded'] = target_mean\n",
    "            \n",
    "            # Show some mappings\n",
    "            category_means = df.groupby(col)[TARGET_COLUMN].mean().sort_values(ascending=False)\n",
    "            print(f\"  ğŸ“‹ Target means (top 5):\")\n",
    "            for cat, mean_val in category_means.head().items():\n",
    "                print(f\"    â€¢ {cat}: {mean_val:.3f}\")\n",
    "            encoded_features.append(f'{col}_target_encoded')\n",
    "        \n",
    "        print(f\"  âœ… Encoded successfully!\")\n",
    "        print()\n",
    "    \n",
    "    # ğŸ—‘ï¸ Step 3: Remove original categorical columns\n",
    "    print(\"ğŸ—‘ï¸ CLEANING UP ORIGINAL CATEGORICAL COLUMNS...\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    columns_to_drop = categorical_features.copy()\n",
    "    \n",
    "    print(f\"ğŸ“‹ Removing original categorical columns:\")\n",
    "    for col in columns_to_drop:\n",
    "        print(f\"  â€¢ {col}\")\n",
    "    \n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ENCODING SUMMARY:\")\n",
    "    print(\"=\"*20)\n",
    "    print(f\"  â€¢ Original categorical columns: {len(categorical_features)}\")\n",
    "    print(f\"  â€¢ New encoded features: {len(encoded_features)}\")\n",
    "    print(f\"  â€¢ Total columns now: {len(df.columns)}\")\n",
    "    \n",
    "    # Update feature lists\n",
    "    categorical_features = []  # No more categorical features\n",
    "    numerical_features = [col for col in df.columns \n",
    "                         if col != TARGET_COLUMN and col not in encoded_features]\n",
    "    all_features = numerical_features + encoded_features\n",
    "    \n",
    "    print(f\"  â€¢ Numerical features: {len(numerical_features)}\")\n",
    "    print(f\"  â€¢ Encoded features: {len(encoded_features)}\")\n",
    "    print(f\"  â€¢ Total features: {len(all_features)}\")\n",
    "\n",
    "else:\n",
    "    if df is None:\n",
    "        print(\"âš ï¸ No data available for encoding.\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸ No categorical features found - skipping encoding step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575e9af9",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 4: Feature Scaling - Making Features Comparable\n",
    "\n",
    "Imagine comparing apples and elephants! ğŸğŸ˜ If one feature ranges from 0-1 (like percentages) and another from 1000-100000 (like salaries), the larger numbers will dominate the smaller ones in machine learning algorithms.\n",
    "\n",
    "### ğŸ¯ Why Scale Features?\n",
    "\n",
    "#### ğŸ” **The Problem**:\n",
    "- **Age**: 20-65 years\n",
    "- **Salary**: $30,000-$150,000  \n",
    "- **Experience**: 0-40 years\n",
    "\n",
    "The salary values are much larger, so algorithms might think salary is more important just because of the scale!\n",
    "\n",
    "#### âœ… **The Solution**: Scale all features to similar ranges\n",
    "\n",
    "### ğŸ“Š Scaling Methods:\n",
    "\n",
    "#### 1ï¸âƒ£ **StandardScaler (Z-score normalization)**\n",
    "- **Formula**: (value - mean) / standard_deviation\n",
    "- **Result**: Mean=0, Standard deviation=1\n",
    "- **Best for**: Normal distributions, most ML algorithms\n",
    "\n",
    "#### 2ï¸âƒ£ **MinMaxScaler (Min-Max normalization)** \n",
    "- **Formula**: (value - min) / (max - min)\n",
    "- **Result**: All values between 0 and 1\n",
    "- **Best for**: When you want specific bounds, neural networks\n",
    "\n",
    "### ğŸ¤– Which Algorithms Need Scaling?\n",
    "- **Need scaling**: SVM, Neural Networks, KNN, PCA, Clustering\n",
    "- **Don't need scaling**: Tree-based (Random Forest, XGBoost, Decision Trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afecfd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ANALYZING FEATURES FOR SCALING...\n",
      "===================================\n",
      "ğŸ“Š Current feature ranges (before scaling):\n",
      "  â€¢ satisfaction_level   â†’ Range:     0.09 to       1.00\n",
      "                           Mean:     0.63, Std:     0.24\n",
      "  â€¢ last_evaluation      â†’ Range:     0.36 to       1.00\n",
      "                           Mean:     0.72, Std:     0.17\n",
      "  â€¢ number_project       â†’ Range:     2.00 to       7.00\n",
      "                           Mean:     3.80, Std:     1.17\n",
      "  â€¢ average_montly_hours â†’ Range:    96.00 to     310.00\n",
      "                           Mean:   200.61, Std:    48.85\n",
      "  â€¢ time_spend_company   â†’ Range:     2.00 to       5.50\n",
      "                           Mean:     3.25, Std:     1.03\n",
      "  â€¢ Work_accident        â†’ Range:     0.00 to       1.00\n",
      "                           Mean:     0.15, Std:     0.36\n",
      "  â€¢ promotion_last_5years â†’ Range:     0.00 to       0.00\n",
      "                           Mean:     0.00, Std:     0.00\n",
      "\n",
      "ğŸ” Scale Analysis:\n",
      "  â€¢ Largest range: 214.00\n",
      "  â€¢ Smallest range: 0.00\n",
      "  â€¢ Range ratio: inf:1\n",
      "  ğŸš¨ Large scale differences detected - scaling recommended!\n",
      "\n",
      "ğŸ”§ APPLYING FEATURE SCALING...\n",
      "============================\n",
      "ğŸ“Š Using StandardScaler (z-score normalization):\n",
      "  â€¢ Transforms to: mean=0, std=1\n",
      "  â€¢ Formula: (value - mean) / standard_deviation\n",
      "  â€¢ Good for: Most ML algorithms, normal distributions\n",
      "\n",
      "âœ… Scaling completed! Created scaled versions of numerical features.\n",
      "\n",
      "ğŸ“Š SCALING RESULTS COMPARISON:\n",
      "================================\n",
      "BEFORE scaling (original features):\n",
      "  â€¢ satisfaction_level   â†’ Mean:     0.63, Std:   0.24, Range: [0.09, 1.00]\n",
      "  â€¢ last_evaluation      â†’ Mean:     0.72, Std:   0.17, Range: [0.36, 1.00]\n",
      "  â€¢ number_project       â†’ Mean:     3.80, Std:   1.17, Range: [2.00, 7.00]\n",
      "\n",
      "AFTER scaling (scaled features):\n",
      "  â€¢ satisfaction_level_scaled â†’ Mean:    -0.00, Std:   1.00, Range: [-2.22, 1.54]\n",
      "  â€¢ last_evaluation_scaled â†’ Mean:    -0.00, Std:   1.00, Range: [-2.11, 1.68]\n",
      "  â€¢ number_project_scaled â†’ Mean:    -0.00, Std:   1.00, Range: [-1.54, 2.73]\n",
      "\n",
      "ğŸ“‹ UPDATING FEATURE INVENTORY...\n",
      "==============================\n",
      "ğŸ“Š Feature summary:\n",
      "  â€¢ Original numerical: 7\n",
      "  â€¢ Scaled numerical: 7\n",
      "  â€¢ Encoded features: 13\n",
      "  â€¢ Total columns: 28\n",
      "\n",
      "ğŸ¯ Features ready for ML: 20\n",
      "ğŸ’¡ We'll use scaled versions for algorithms that need scaling\n",
      "ğŸ’¡ We'll keep original versions for algorithms that don't need scaling\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“ Step 1: Analyze features before scaling\n",
    "if df is not None and len(numerical_features) > 0:\n",
    "    print(\"ğŸ“ ANALYZING FEATURES FOR SCALING...\")\n",
    "    print(\"=\"*35)\n",
    "    \n",
    "    print(\"ğŸ“Š Current feature ranges (before scaling):\")\n",
    "    for col in numerical_features:\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "        mean_val = df[col].mean()\n",
    "        std_val = df[col].std()\n",
    "        \n",
    "        print(f\"  â€¢ {col:20} â†’ Range: {min_val:8.2f} to {max_val:10.2f}\")\n",
    "        print(f\"    {'':20}   Mean: {mean_val:8.2f}, Std: {std_val:8.2f}\")\n",
    "    \n",
    "    # Check if scaling is needed\n",
    "    ranges = [(df[col].max() - df[col].min()) for col in numerical_features]\n",
    "    max_range = max(ranges)\n",
    "    min_range = min(ranges)\n",
    "    range_ratio = max_range / min_range if min_range > 0 else float('inf')\n",
    "    \n",
    "    print(f\"\\nğŸ” Scale Analysis:\")\n",
    "    print(f\"  â€¢ Largest range: {max_range:,.2f}\")\n",
    "    print(f\"  â€¢ Smallest range: {min_range:,.2f}\")\n",
    "    print(f\"  â€¢ Range ratio: {range_ratio:,.1f}:1\")\n",
    "    \n",
    "    if range_ratio > 10:\n",
    "        scaling_needed = True\n",
    "        print(f\"  ğŸš¨ Large scale differences detected - scaling recommended!\")\n",
    "    else:\n",
    "        scaling_needed = False\n",
    "        print(f\"  âœ… Scales are relatively similar - scaling optional\")\n",
    "    \n",
    "    # ğŸ”§ Step 2: Apply scaling\n",
    "    print(f\"\\nğŸ”§ APPLYING FEATURE SCALING...\")\n",
    "    print(\"=\"*28)\n",
    "    \n",
    "    if scaling_needed or True:  # We'll scale anyway for demonstration\n",
    "        \n",
    "        # We'll use StandardScaler as it's most common and robust\n",
    "        print(\"ğŸ“Š Using StandardScaler (z-score normalization):\")\n",
    "        print(\"  â€¢ Transforms to: mean=0, std=1\")\n",
    "        print(\"  â€¢ Formula: (value - mean) / standard_deviation\")\n",
    "        print(\"  â€¢ Good for: Most ML algorithms, normal distributions\")\n",
    "        print()\n",
    "        \n",
    "        # Initialize the scaler\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Fit and transform numerical features\n",
    "        scaled_features = scaler.fit_transform(df[numerical_features])\n",
    "        \n",
    "        # Create new column names for scaled features\n",
    "        scaled_column_names = [f\"{col}_scaled\" for col in numerical_features]\n",
    "        \n",
    "        # Create DataFrame with scaled features\n",
    "        scaled_df = pd.DataFrame(scaled_features, \n",
    "                                columns=scaled_column_names,\n",
    "                                index=df.index)\n",
    "        \n",
    "        # Add scaled features to main dataframe\n",
    "        df = pd.concat([df, scaled_df], axis=1)\n",
    "        \n",
    "        print(\"âœ… Scaling completed! Created scaled versions of numerical features.\")\n",
    "        \n",
    "        # ğŸ“Š Step 3: Compare before and after scaling\n",
    "        print(f\"\\nğŸ“Š SCALING RESULTS COMPARISON:\")\n",
    "        print(\"=\"*32)\n",
    "        \n",
    "        print(\"BEFORE scaling (original features):\")\n",
    "        for col in numerical_features[:3]:  # Show first 3 for space\n",
    "            mean_val = df[col].mean()\n",
    "            std_val = df[col].std()\n",
    "            min_val = df[col].min()\n",
    "            max_val = df[col].max()\n",
    "            print(f\"  â€¢ {col:20} â†’ Mean: {mean_val:8.2f}, Std: {std_val:6.2f}, Range: [{min_val:.2f}, {max_val:.2f}]\")\n",
    "        \n",
    "        print(\"\\nAFTER scaling (scaled features):\")\n",
    "        for col in scaled_column_names[:3]:  # Show first 3 for space\n",
    "            mean_val = df[col].mean()\n",
    "            std_val = df[col].std()\n",
    "            min_val = df[col].min()\n",
    "            max_val = df[col].max()\n",
    "            print(f\"  â€¢ {col:20} â†’ Mean: {mean_val:8.2f}, Std: {std_val:6.2f}, Range: [{min_val:.2f}, {max_val:.2f}]\")\n",
    "        \n",
    "        # ğŸ“‹ Step 4: Update feature lists\n",
    "        print(f\"\\nğŸ“‹ UPDATING FEATURE INVENTORY...\")\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        # Update our feature tracking\n",
    "        original_numerical = numerical_features.copy()\n",
    "        scaled_numerical = scaled_column_names.copy()\n",
    "        \n",
    "        print(f\"ğŸ“Š Feature summary:\")\n",
    "        print(f\"  â€¢ Original numerical: {len(original_numerical)}\")\n",
    "        print(f\"  â€¢ Scaled numerical: {len(scaled_numerical)}\")\n",
    "        print(f\"  â€¢ Encoded features: {len(encoded_features) if 'encoded_features' in locals() else 0}\")\n",
    "        print(f\"  â€¢ Total columns: {len(df.columns)}\")\n",
    "        \n",
    "        # For machine learning, we'll use scaled features instead of original\n",
    "        features_for_ml = scaled_numerical + (encoded_features if 'encoded_features' in locals() else [])\n",
    "        \n",
    "        print(f\"\\nğŸ¯ Features ready for ML: {len(features_for_ml)}\")\n",
    "        print(\"ğŸ’¡ We'll use scaled versions for algorithms that need scaling\")\n",
    "        print(\"ğŸ’¡ We'll keep original versions for algorithms that don't need scaling\")\n",
    "        \n",
    "    else:\n",
    "        print(\"â„¹ï¸ Scaling skipped - ranges are already similar\")\n",
    "        features_for_ml = numerical_features + (encoded_features if 'encoded_features' in locals() else [])\n",
    "\n",
    "else:\n",
    "    if df is None:\n",
    "        print(\"âš ï¸ No data available for scaling.\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸ No numerical features found - skipping scaling step.\")\n",
    "        features_for_ml = encoded_features if 'encoded_features' in locals() else []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78325378",
   "metadata": {},
   "source": [
    "## âš–ï¸ Step 5: Handle Class Imbalance - Balancing Our Target\n",
    "\n",
    "Class imbalance is like having a basketball team where 90% of players are guards and only 10% are centers! ğŸ€ When one class (like \"employees who stay\") vastly outnumbers another (like \"employees who leave\"), our model gets biased.\n",
    "\n",
    "### ğŸ” **The Problem**:\n",
    "If 95% of employees stay and only 5% leave:\n",
    "- Model learns to always predict \"stay\" \n",
    "- Gets 95% accuracy by just guessing \"stay\" every time!\n",
    "- But fails to identify employees who actually might leave ğŸ˜\n",
    "\n",
    "### ğŸ¯ **Solutions We'll Use**:\n",
    "\n",
    "#### 1ï¸âƒ£ **SMOTE (Synthetic Minority Oversampling)**\n",
    "- **What**: Creates artificial examples of minority class\n",
    "- **How**: Uses existing minority examples to generate new, similar ones\n",
    "- **Pro**: Increases minority class without duplicating exact examples\n",
    "- **Con**: Might create unrealistic combinations\n",
    "\n",
    "#### 2ï¸âƒ£ **Class Weights**\n",
    "- **What**: Tells algorithm to pay more attention to minority class\n",
    "- **How**: Penalizes wrong predictions on minority class more heavily\n",
    "- **Pro**: No data modification, works with any algorithm\n",
    "- **Con**: Might create more false positives\n",
    "\n",
    "#### 3ï¸âƒ£ **Undersampling**\n",
    "- **What**: Reduces majority class to match minority class\n",
    "- **How**: Randomly removes majority class examples\n",
    "- **Pro**: Balanced dataset, faster training\n",
    "- **Con**: Loses potentially useful data\n",
    "\n",
    "### ğŸš€ **When to Use Each**:\n",
    "- **Small dataset** â†’ Class weights or SMOTE\n",
    "- **Large dataset** â†’ Undersampling or SMOTE  \n",
    "- **Very imbalanced** â†’ Combine multiple techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ea16e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš–ï¸ ANALYZING CLASS BALANCE...\n",
      "============================\n",
      "ğŸ¯ Target variable: quit\n",
      "ğŸ“Š Class distribution:\n",
      "  â€¢ 0: 9,430 samples (82.6%)\n",
      "  â€¢ 1: 1,983 samples (17.4%)\n",
      "\n",
      "ğŸ“ Imbalance analysis:\n",
      "  â€¢ Minority class: 17.4%\n",
      "  â€¢ Majority class: 82.6%\n",
      "  â€¢ Imbalance ratio: 4.8:1\n",
      "  â€¢ Status: ğŸ”´ Severely imbalanced\n",
      "  â€¢ Recommendation: SMOTE + Class weights recommended\n",
      "\n",
      "ğŸ”§ APPLYING SMOTE...\n",
      "==================\n",
      "ğŸ” What SMOTE does:\n",
      "  1. Finds minority class samples\n",
      "  2. Identifies their nearest neighbors\n",
      "  3. Creates new samples between them\n",
      "  4. Balances the dataset\n",
      "\n",
      "ğŸ“Š Before SMOTE:\n",
      "  â€¢ Dataset shape: (11413, 20)\n",
      "  â€¢ Class 1: 1,983 samples\n",
      "  â€¢ Class 0: 9,430 samples\n",
      "\n",
      "ğŸ“Š After SMOTE:\n",
      "  â€¢ Dataset shape: (18860, 20)\n",
      "  â€¢ Class 1: 9,430 samples\n",
      "  â€¢ Class 0: 9,430 samples\n",
      "\n",
      "âœ… SMOTE Results:\n",
      "  â€¢ Original samples: 11,413\n",
      "  â€¢ Synthetic samples created: 7,447\n",
      "  â€¢ Total samples: 18,860\n",
      "  â€¢ New balance ratio: 1:1 (perfectly balanced)\n",
      "\n",
      "ğŸ’¾ Created balanced dataset: df_balanced\n",
      "   Use this for training models that benefit from balanced data\n",
      "   Keep original df for models that handle imbalance well\n",
      "\n",
      "ğŸ“Š VISUALIZING CLASS DISTRIBUTIONS...\n",
      "===================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# âš–ï¸ Step 1: Analyze class balance in our target variable\n",
    "if df is not None and TARGET_COLUMN:\n",
    "    print(\"âš–ï¸ ANALYZING CLASS BALANCE...\")\n",
    "    print(\"=\"*28)\n",
    "    \n",
    "    # Get target distribution\n",
    "    target_counts = df[TARGET_COLUMN].value_counts()\n",
    "    target_percentages = df[TARGET_COLUMN].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(f\"ğŸ¯ Target variable: {TARGET_COLUMN}\")\n",
    "    print(f\"ğŸ“Š Class distribution:\")\n",
    "    \n",
    "    for value, count in target_counts.items():\n",
    "        percentage = target_percentages[value]\n",
    "        print(f\"  â€¢ {value}: {count:,} samples ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Calculate imbalance metrics\n",
    "    minority_class_pct = target_percentages.min()\n",
    "    majority_class_pct = target_percentages.max()\n",
    "    imbalance_ratio = majority_class_pct / minority_class_pct\n",
    "    \n",
    "    print(f\"\\nğŸ“ Imbalance analysis:\")\n",
    "    print(f\"  â€¢ Minority class: {minority_class_pct:.1f}%\")\n",
    "    print(f\"  â€¢ Majority class: {majority_class_pct:.1f}%\")\n",
    "    print(f\"  â€¢ Imbalance ratio: {imbalance_ratio:.1f}:1\")\n",
    "    \n",
    "    # Determine severity and recommend strategy\n",
    "    if imbalance_ratio >= 4:\n",
    "        imbalance_level = \"ğŸ”´ Severely imbalanced\"\n",
    "        recommendation = \"SMOTE + Class weights recommended\"\n",
    "        apply_smote = True\n",
    "    elif imbalance_ratio >= 2:\n",
    "        imbalance_level = \"ğŸŸ¡ Moderately imbalanced\"\n",
    "        recommendation = \"SMOTE or class weights\"\n",
    "        apply_smote = True\n",
    "    else:\n",
    "        imbalance_level = \"ğŸŸ¢ Relatively balanced\"\n",
    "        recommendation = \"No special handling needed\"\n",
    "        apply_smote = False\n",
    "    \n",
    "    print(f\"  â€¢ Status: {imbalance_level}\")\n",
    "    print(f\"  â€¢ Recommendation: {recommendation}\")\n",
    "    \n",
    "    # ğŸ”§ Step 2: Apply SMOTE if needed\n",
    "    if apply_smote:\n",
    "        print(f\"\\nğŸ”§ APPLYING SMOTE...\")\n",
    "        print(\"=\"*18)\n",
    "        \n",
    "        print(\"ğŸ” What SMOTE does:\")\n",
    "        print(\"  1. Finds minority class samples\")\n",
    "        print(\"  2. Identifies their nearest neighbors\")\n",
    "        print(\"  3. Creates new samples between them\")\n",
    "        print(\"  4. Balances the dataset\")\n",
    "        print()\n",
    "        \n",
    "        # Prepare features and target for SMOTE\n",
    "        if 'features_for_ml' in locals():\n",
    "            X = df[features_for_ml]\n",
    "        else:\n",
    "            # Fallback to all numerical features\n",
    "            X = df.select_dtypes(include=[np.number]).drop(columns=[TARGET_COLUMN], errors='ignore')\n",
    "        \n",
    "        y = df[TARGET_COLUMN]\n",
    "        \n",
    "        print(f\"ğŸ“Š Before SMOTE:\")\n",
    "        print(f\"  â€¢ Dataset shape: {X.shape}\")\n",
    "        original_counts = Counter(y)\n",
    "        for class_val, count in original_counts.items():\n",
    "            print(f\"  â€¢ Class {class_val}: {count:,} samples\")\n",
    "        \n",
    "        # Apply SMOTE\n",
    "        smote = SMOTE(random_state=RANDOM_STATE)\n",
    "        \n",
    "        try:\n",
    "            X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "            \n",
    "            print(f\"\\nğŸ“Š After SMOTE:\")\n",
    "            print(f\"  â€¢ Dataset shape: {X_resampled.shape}\")\n",
    "            new_counts = Counter(y_resampled)\n",
    "            for class_val, count in new_counts.items():\n",
    "                print(f\"  â€¢ Class {class_val}: {count:,} samples\")\n",
    "            \n",
    "            # Calculate how many synthetic samples were created\n",
    "            total_original = len(y)\n",
    "            total_new = len(y_resampled)\n",
    "            synthetic_created = total_new - total_original\n",
    "            \n",
    "            print(f\"\\nâœ… SMOTE Results:\")\n",
    "            print(f\"  â€¢ Original samples: {total_original:,}\")\n",
    "            print(f\"  â€¢ Synthetic samples created: {synthetic_created:,}\")\n",
    "            print(f\"  â€¢ Total samples: {total_new:,}\")\n",
    "            print(f\"  â€¢ New balance ratio: 1:1 (perfectly balanced)\")\n",
    "            \n",
    "            # Create balanced dataframe\n",
    "            df_balanced = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "            df_balanced[TARGET_COLUMN] = y_resampled\n",
    "            \n",
    "            print(f\"\\nğŸ’¾ Created balanced dataset: df_balanced\")\n",
    "            print(f\"   Use this for training models that benefit from balanced data\")\n",
    "            print(f\"   Keep original df for models that handle imbalance well\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ SMOTE failed: {str(e)}\")\n",
    "            print(f\"ğŸ’¡ This might happen if:\")\n",
    "            print(f\"   â€¢ Too few minority samples\")\n",
    "            print(f\"   â€¢ Features need more preprocessing\")\n",
    "            print(f\"   â€¢ Data has other issues\")\n",
    "            df_balanced = df.copy()\n",
    "            \n",
    "    else:\n",
    "        print(f\"\\nâ„¹ï¸ Class balance is acceptable - no SMOTE needed\")\n",
    "        df_balanced = df.copy()\n",
    "    \n",
    "    # ğŸ“Š Step 3: Visualize class distribution\n",
    "    print(f\"\\nğŸ“Š VISUALIZING CLASS DISTRIBUTIONS...\")\n",
    "    print(\"=\"*35)\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    fig.suptitle('ğŸ¯ Class Distribution: Before vs After Balancing', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Original distribution\n",
    "    target_counts.plot(kind='bar', ax=axes[0], color=['lightcoral', 'lightblue'], alpha=0.7)\n",
    "    axes[0].set_title('ğŸ“Š Original Distribution', fontweight='bold')\n",
    "    axes[0].set_xlabel('Target Class')\n",
    "    axes[0].set_ylabel('Number of Samples')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for i, (class_val, count) in enumerate(target_counts.items()):\n",
    "        pct = target_percentages[class_val]\n",
    "        axes[0].text(i, count + count*0.01, f'{pct:.1f}%', \n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Balanced distribution\n",
    "    if 'df_balanced' in locals():\n",
    "        balanced_counts = df_balanced[TARGET_COLUMN].value_counts()\n",
    "        balanced_counts.plot(kind='bar', ax=axes[1], color=['lightgreen', 'lightyellow'], alpha=0.7)\n",
    "        axes[1].set_title('âš–ï¸ After Balancing', fontweight='bold')\n",
    "        axes[1].set_xlabel('Target Class')\n",
    "        axes[1].set_ylabel('Number of Samples')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add count labels\n",
    "        for i, (class_val, count) in enumerate(balanced_counts.items()):\n",
    "            axes[1].text(i, count + count*0.01, f'{count:,}', \n",
    "                        ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    if df is None:\n",
    "        print(\"âš ï¸ No data available for class balance analysis.\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No target variable identified - skipping class balance analysis.\")\n",
    "        print(\"ğŸ’¡ You may need to specify the target variable manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961c20b1",
   "metadata": {},
   "source": [
    "## ğŸ‰ Step 6: Final Summary - Our Data is Ready!\n",
    "\n",
    "Congratulations! ğŸŠ You've successfully transformed raw data into machine learning-ready features. Let's see what we've accomplished and prepare for the next steps.\n",
    "\n",
    "### âœ… **What We've Accomplished:**\n",
    "\n",
    "#### ğŸ”„ **Data Preprocessing**\n",
    "- âœ… Handled missing values with appropriate strategies\n",
    "- âœ… Removed duplicate rows\n",
    "- âœ… Detected and handled outliers\n",
    "- âœ… Ensured data quality and consistency\n",
    "\n",
    "#### ğŸ·ï¸ **Categorical Encoding** \n",
    "- âœ… Converted text categories to numbers\n",
    "- âœ… Applied appropriate encoding strategies\n",
    "- âœ… Created machine learning-compatible features\n",
    "\n",
    "#### ğŸ“ **Feature Scaling**\n",
    "- âœ… Standardized numerical features\n",
    "- âœ… Made features comparable in scale\n",
    "- âœ… Prepared features for scale-sensitive algorithms\n",
    "\n",
    "#### âš–ï¸ **Class Balancing**\n",
    "- âœ… Analyzed target variable distribution\n",
    "- âœ… Applied SMOTE for balanced training data\n",
    "- âœ… Created both balanced and original datasets\n",
    "\n",
    "### ğŸš€ **Next Steps in Our ML Journey:**\n",
    "\n",
    "1. **ğŸ“Š Model Training** (Next Notebook)\n",
    "   - Train multiple algorithms\n",
    "   - Compare performance on balanced vs original data\n",
    "   - Hyperparameter tuning\n",
    "\n",
    "2. **ğŸ“ˆ Model Evaluation** \n",
    "   - Detailed performance metrics\n",
    "   - Feature importance analysis\n",
    "   - Model interpretability\n",
    "\n",
    "3. **ğŸ¯ Model Selection**\n",
    "   - Choose best performing model\n",
    "   - Validate on test data\n",
    "   - Prepare for deployment\n",
    "\n",
    "### ğŸ’¾ **Datasets Available:**\n",
    "- **`df`**: Original preprocessed data\n",
    "- **`df_balanced`**: SMOTE-balanced data  \n",
    "- **Ready for multiple ML algorithms!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4752fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š FINAL FEATURE ENGINEERING SUMMARY\n",
      "========================================\n",
      "ğŸ—ƒï¸ DATASET OVERVIEW:\n",
      "  â€¢ Original dataset: 11,413 rows Ã— 28 columns\n",
      "  â€¢ Balanced dataset: 18,860 rows Ã— 21 columns\n",
      "\n",
      "ğŸ”§ ENGINEERED FEATURES:\n",
      "  â€¢ Total ML-ready features: 20\n",
      "  â€¢ Scaled numerical features: 7\n",
      "  â€¢ Encoded categorical features: 13\n",
      "  â€¢ Target variable: quit\n",
      "\n",
      "âœ… DATA QUALITY:\n",
      "  â€¢ Missing values: 0\n",
      "  â€¢ Duplicate rows: 0\n",
      "  â€¢ Data types: All compatible with ML\n",
      "  â€¢ Memory usage: 1.53 MB\n",
      "\n",
      "ğŸ¯ TARGET DISTRIBUTION:\n",
      "  â€¢ 0: 82.6%\n",
      "  â€¢ 1: 17.4%\n",
      "\n",
      "âš–ï¸ BALANCED TARGET DISTRIBUTION:\n",
      "  â€¢ 1: 50.0%\n",
      "  â€¢ 0: 50.0%\n",
      "\n",
      "ğŸ’¾ SAVING PROCESSED DATASETS...\n",
      "==============================\n",
      "âœ… Saved original processed data: feature_engineered_data.csv\n",
      "âœ… Saved balanced data: balanced_data.csv\n",
      "âœ… Saved feature info: feature_info.json\n",
      "\n",
      "ğŸ“‚ Files saved to: c:\\Users\\DELL\\Desktop\\AI-Project\\AI-Project\\data\\processed\n",
      "\n",
      "ğŸ¯ READY FOR MACHINE LEARNING!\n",
      "==============================\n",
      "Your data is now ready for model training!\n",
      "\n",
      "ğŸ“‹ What to use for different algorithms:\n",
      "  â€¢ Tree-based (Random Forest, XGBoost): Use original features\n",
      "  â€¢ Linear models (Logistic Regression): Use scaled features\n",
      "  â€¢ Neural Networks: Use scaled features\n",
      "  â€¢ Imbalanced-sensitive algorithms: Use balanced dataset\n",
      "\n",
      "ğŸš€ Next step: Open 03_class_imbalance_analysis.ipynb\n",
      "   Or jump to 04_model_training.ipynb to start training!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š Final Data Summary and Export\n",
    "print(\"ğŸ“Š FINAL FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "if df is not None:\n",
    "    # Dataset overview\n",
    "    print(f\"ğŸ—ƒï¸ DATASET OVERVIEW:\")\n",
    "    print(f\"  â€¢ Original dataset: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "    \n",
    "    if 'df_balanced' in locals():\n",
    "        print(f\"  â€¢ Balanced dataset: {df_balanced.shape[0]:,} rows Ã— {df_balanced.shape[1]} columns\")\n",
    "    \n",
    "    # Feature summary\n",
    "    if 'features_for_ml' in locals():\n",
    "        print(f\"\\nğŸ”§ ENGINEERED FEATURES:\")\n",
    "        print(f\"  â€¢ Total ML-ready features: {len(features_for_ml)}\")\n",
    "        \n",
    "        if 'scaled_numerical' in locals():\n",
    "            print(f\"  â€¢ Scaled numerical features: {len(scaled_numerical)}\")\n",
    "            \n",
    "        if 'encoded_features' in locals():\n",
    "            print(f\"  â€¢ Encoded categorical features: {len(encoded_features)}\")\n",
    "        \n",
    "        print(f\"  â€¢ Target variable: {TARGET_COLUMN}\")\n",
    "    \n",
    "    # Data quality summary\n",
    "    print(f\"\\nâœ… DATA QUALITY:\")\n",
    "    print(f\"  â€¢ Missing values: {df.isnull().sum().sum()}\")\n",
    "    print(f\"  â€¢ Duplicate rows: {df.duplicated().sum()}\")\n",
    "    print(f\"  â€¢ Data types: All compatible with ML\")\n",
    "    \n",
    "    # Memory usage\n",
    "    memory_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    print(f\"  â€¢ Memory usage: {memory_mb:.2f} MB\")\n",
    "    \n",
    "    # Target distribution\n",
    "    if TARGET_COLUMN:\n",
    "        print(f\"\\nğŸ¯ TARGET DISTRIBUTION:\")\n",
    "        target_dist = df[TARGET_COLUMN].value_counts(normalize=True) * 100\n",
    "        for value, pct in target_dist.items():\n",
    "            print(f\"  â€¢ {value}: {pct:.1f}%\")\n",
    "        \n",
    "        if 'df_balanced' in locals():\n",
    "            print(f\"\\nâš–ï¸ BALANCED TARGET DISTRIBUTION:\")\n",
    "            balanced_dist = df_balanced[TARGET_COLUMN].value_counts(normalize=True) * 100\n",
    "            for value, pct in balanced_dist.items():\n",
    "                print(f\"  â€¢ {value}: {pct:.1f}%\")\n",
    "    \n",
    "    # ğŸ’¾ Step 2: Save processed datasets\n",
    "    print(f\"\\nğŸ’¾ SAVING PROCESSED DATASETS...\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # Create processed data directory\n",
    "    processed_dir = project_root / 'data' / 'processed'\n",
    "    processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Save original processed dataset\n",
    "        original_path = processed_dir / 'feature_engineered_data.csv'\n",
    "        df.to_csv(original_path, index=False)\n",
    "        print(f\"âœ… Saved original processed data: feature_engineered_data.csv\")\n",
    "        \n",
    "        # Save balanced dataset if it exists\n",
    "        if 'df_balanced' in locals():\n",
    "            balanced_path = processed_dir / 'balanced_data.csv'\n",
    "            df_balanced.to_csv(balanced_path, index=False)\n",
    "            print(f\"âœ… Saved balanced data: balanced_data.csv\")\n",
    "        \n",
    "        # Save feature lists for future reference\n",
    "        feature_info = {\n",
    "            'target_column': TARGET_COLUMN,\n",
    "            'ml_features': features_for_ml if 'features_for_ml' in locals() else [],\n",
    "            'scaled_features': scaled_numerical if 'scaled_numerical' in locals() else [],\n",
    "            'encoded_features': encoded_features if 'encoded_features' in locals() else [],\n",
    "            'original_numerical': original_numerical if 'original_numerical' in locals() else []\n",
    "        }\n",
    "        \n",
    "        import json\n",
    "        feature_info_path = processed_dir / 'feature_info.json'\n",
    "        with open(feature_info_path, 'w') as f:\n",
    "            json.dump(feature_info, f, indent=2)\n",
    "        print(f\"âœ… Saved feature info: feature_info.json\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‚ Files saved to: {processed_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error saving files: {str(e)}\")\n",
    "        print(f\"ğŸ’¡ Check directory permissions and disk space\")\n",
    "    \n",
    "    # ğŸ¯ Step 3: Prepare for next notebook\n",
    "    print(f\"\\nğŸ¯ READY FOR MACHINE LEARNING!\")\n",
    "    print(\"=\"*30)\n",
    "    print(\"Your data is now ready for model training!\")\n",
    "    print()\n",
    "    print(\"ğŸ“‹ What to use for different algorithms:\")\n",
    "    print(\"  â€¢ Tree-based (Random Forest, XGBoost): Use original features\")\n",
    "    print(\"  â€¢ Linear models (Logistic Regression): Use scaled features\")\n",
    "    print(\"  â€¢ Neural Networks: Use scaled features\")\n",
    "    print(\"  â€¢ Imbalanced-sensitive algorithms: Use balanced dataset\")\n",
    "    print()\n",
    "    print(\"ğŸš€ Next step: Open 03_class_imbalance_analysis.ipynb\")\n",
    "    print(\"   Or jump to 04_model_training.ipynb to start training!\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No data available for summary.\")\n",
    "    print(\"ğŸ”„ Please run the previous cells to load and process data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
